{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from evaluation.utils import entropy_batch_mixing, knn_purity, nmi, asw_c, asw_b\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "import json\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_umaps = False\n",
    "calc_metrics = True\n",
    "\n",
    "figure = 0\n",
    "\n",
    "# 'scvi' or 'scanvi'\n",
    "model = \"scanvi\"\n",
    "\n",
    "# Choose results of deeply injected model or first injected model\n",
    "deep_conds = [False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Figure 3 and Full Integration choose dataset 'pancreas' or 'brain'\n",
    "data = \"immune_all_human_fig6\"\n",
    "\n",
    "# For Figure 3, 4, 6 choose Test number (Reference to Query ratio)\n",
    "test_nrs = [1,2,3,4]\n",
    "\n",
    "# For Figure 5 choose OOD experiment\n",
    "ood_nr = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " data\n",
      "KNN-P: 0.8512045588902957\n",
      "NMI: 0.83753433511914\n",
      "ASW_C: 0.6124978512525558\n",
      "EBM: 1.094349221170563\n",
      "ASW_B: 0.8796035298837446\n",
      "Accuracy: 0.6169963941136342\n",
      "F1: 0.41908125400989277\n",
      "\n",
      " data\n",
      "KNN-P: 0.8887656978196015\n",
      "NMI: 0.8362416784957047\n",
      "ASW_C: 0.6132574453949928\n",
      "EBM: 1.0462352092278806\n",
      "ASW_B: 0.8708133441505143\n",
      "Accuracy: 0.7572848650229023\n",
      "F1: 0.7848447529893625\n",
      "\n",
      " data\n",
      "KNN-P: 0.8993511403678773\n",
      "NMI: 0.8814800671154073\n",
      "ASW_C: 0.6390130817890167\n",
      "EBM: 0.9997285993186966\n",
      "ASW_B: 0.8740928035804669\n",
      "Accuracy: 0.9602377935873696\n",
      "F1: 0.9022509039677982\n",
      "\n",
      " data\n",
      "KNN-P: 0.9023425448171014\n",
      "NMI: 0.8950898492331538\n",
      "ASW_C: 0.6417775899171829\n",
      "EBM: 1.0215162708899723\n",
      "ASW_B: 0.875279453138082\n",
      "Accuracy: 0.9643309618945521\n",
      "F1: 0.9013063912172454\n"
     ]
    }
   ],
   "source": [
    "if figure == 1 or figure == 7 or figure == 5 or (figure == 0 and model == 'scvi'):\n",
    "    test_nrs = [0]\n",
    "if figure == 0:\n",
    "    deep_conds = [True]\n",
    "for deep_cond in deep_conds:\n",
    "    for test_nr in test_nrs:\n",
    "        if deep_cond:\n",
    "            deep_label = \"deep_cond\"\n",
    "        else:\n",
    "            deep_label = \"first_cond\"\n",
    "        if figure == 0:\n",
    "            if model == 'scvi':\n",
    "                dir_path = os.path.expanduser(f'~/Documents/benchmarking_adata/full_integration/{model}/{data}/')\n",
    "            else:\n",
    "                dir_path = os.path.expanduser(f'~/Documents/benchmarking_adata/full_integration/{model}/{data}/label_ratio_{test_nr}/')  \n",
    "        if figure == 1:\n",
    "            dir_path = os.path.expanduser(f'~/Documents/benchmarking_adata/figure_1/{model}/{deep_label}/')\n",
    "        elif figure == 3:\n",
    "            dir_path = os.path.expanduser(f'~/Documents/benchmarking_adata/figure_3/{model}/{data}/test_{test_nr}_{deep_label}/')\n",
    "        elif figure == 4:\n",
    "            dir_path = os.path.expanduser(f'~/Documents/benchmarking_adata/figure_4/{model}/test_{test_nr}_{deep_label}/')\n",
    "        elif figure == 5:\n",
    "            dir_path = os.path.expanduser(f'~/Documents/benchmarking_adata/figure_5/{model}/ood_{ood_nr}_{deep_label}/')\n",
    "        elif figure == 6:\n",
    "            dir_path = os.path.expanduser(f'~/Documents/benchmarking_adata/figure_6/{model}/test_{test_nr}_{deep_label}/')\n",
    "        elif figure == 7:\n",
    "            dir_path = os.path.expanduser(f'~/Documents/benchmarking_adata/figure_7/{model}/{deep_label}/')\n",
    "            \n",
    "        adata_dict = dict()\n",
    "        for file in os.listdir(dir_path):\n",
    "            if file.endswith(\".h5ad\"):\n",
    "                adata_dict[os.path.splitext(file)[0]] = sc.read(os.path.join(dir_path, file))\n",
    "                \n",
    "        if save_umaps:\n",
    "            for key, value in adata_dict.items():\n",
    "                sc.pp.neighbors(value)\n",
    "                sc.tl.leiden(value)\n",
    "                sc.tl.umap(value)\n",
    "                plt.figure()\n",
    "                sc.pl.umap(\n",
    "                    value,\n",
    "                    color=[\"batch\", \"celltype\"],\n",
    "                    frameon=False,\n",
    "                    ncols=1,\n",
    "                    show=False\n",
    "                )\n",
    "                plt.savefig(f'{dir_path}{key}_umap.png', bbox_inches='tight')\n",
    "                if model == \"scanvi\":\n",
    "                    sc.pl.umap(\n",
    "                        value,\n",
    "                        color=[\"predictions\", \"celltype\"],\n",
    "                        frameon=False,\n",
    "                        ncols=1,\n",
    "                        show=False\n",
    "                    )\n",
    "                    plt.savefig(f'{dir_path}{key}_umap_pred.png', bbox_inches='tight')\n",
    "                    \n",
    "        if calc_metrics:\n",
    "            results = dict()\n",
    "            for key, adata in adata_dict.items():\n",
    "                print(\"\\n\", key)\n",
    "                data_result = dict()\n",
    "                knn_s = knn_purity(adata)\n",
    "                nmi_s = nmi(adata)\n",
    "                asw_c_s = asw_c(adata)\n",
    "                bio_con = (knn_s + nmi_s + asw_c_s) / 3\n",
    "                if len(np.unique(adata.obs.batch).tolist()) > 1:\n",
    "                    ebm_s = entropy_batch_mixing(adata)\n",
    "                    asw_b_s = asw_b(adata)\n",
    "                    batch_mix = (ebm_s + asw_b_s) / 2\n",
    "                    latent_overall = (batch_mix + bio_con) / 2\n",
    "                else:\n",
    "                    ebm_s = asw_b_s = batch_mix = 0\n",
    "                    latent_overall = bio_con\n",
    "                data_result[\"latent_score\"] = latent_overall\n",
    "                data_result[\"batch_mixing\"] = batch_mix\n",
    "                data_result[\"bio_conservation\"] = bio_con\n",
    "                data_result[\"ebm\"] = ebm_s\n",
    "                data_result[\"knn\"] = knn_s\n",
    "                data_result[\"nmi\"] = nmi_s\n",
    "                data_result[\"asw_b\"] = asw_b_s\n",
    "                data_result[\"asw_c\"] = asw_c_s\n",
    "                if model ==\"scanvi\":\n",
    "                    data_result[\"accuracy\"] = np.mean(adata.obs.predictions == adata.obs.celltype.tolist())\n",
    "                    print(\"Accuracy:\", data_result[\"accuracy\"])\n",
    "                    data_result[\"f1\"] = f1_score(adata.obs.predictions, adata.obs.celltype, average='macro')\n",
    "                    print(\"F1:\", data_result[\"f1\"])\n",
    "                results[key] = data_result\n",
    "                \n",
    "        with open(f'{dir_path}metric_scores.txt', 'w') as filehandle:\n",
    "            json.dump(results, filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scvi_benchmarking",
   "language": "python",
   "name": "scvi_benchmarking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

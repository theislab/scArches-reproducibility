{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./\")\n",
    "\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import entropy, itemfreq\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.metrics import adjusted_rand_score as ARI\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "from sklearn.metrics import silhouette_score\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import csv\n",
    "import scanorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_scores(labels, newX, batch_ind):\n",
    "    n_labels = labels.nunique()\n",
    "    labels_pred = KMeans(n_labels, n_init=200).fit_predict(newX)\n",
    "    asw_score = silhouette_score(newX, batch_ind)\n",
    "    nmi_score = NMI(labels, labels_pred)\n",
    "    ari_score = ARI(labels, labels_pred)\n",
    "        \n",
    "    return asw_score, nmi_score, ari_score   \n",
    "\n",
    "def knn_purity(adata, label_key, n_neighbors=30):\n",
    "    labels = LabelEncoder().fit_transform(adata.obs[label_key].to_numpy())\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1).fit(adata.X)\n",
    "    indices = nbrs.kneighbors(adata.X, return_distance=False)[:, 1:]\n",
    "    neighbors_labels = np.vectorize(lambda i: labels[i])(indices)\n",
    "\n",
    "    # pre cell purity scores\n",
    "    scores = ((neighbors_labels - labels.reshape(-1, 1)) == 0).mean(axis=1)\n",
    "    res = [\n",
    "        np.mean(scores[labels == i]) for i in np.unique(labels)\n",
    "    ]  # per cell-type purity\n",
    "\n",
    "    return np.mean(res)\n",
    "\n",
    "def entropy_batch_mixing(latent, labels, n_neighbors=50, n_pools=50, n_samples_per_pool=100):\n",
    "    \n",
    "    def entropy_from_indices(indices):\n",
    "        return entropy(np.array(itemfreq(indices)[:, 1].astype(np.int32)))\n",
    "\n",
    "    neighbors = NearestNeighbors(n_neighbors=n_neighbors + 1).fit(latent)\n",
    "    indices = neighbors.kneighbors(latent, return_distance=False)[:, 1:]\n",
    "    batch_indices = np.vectorize(lambda i: labels[i])(indices)\n",
    "\n",
    "    entropies = np.apply_along_axis(entropy_from_indices, axis=1, arr=batch_indices)\n",
    "\n",
    "    # average n_pools entropy results where each result is an average of n_samples_per_pool random samples.\n",
    "    if n_pools == 1:\n",
    "        score = np.mean(entropies)\n",
    "    else:\n",
    "        score = np.mean([\n",
    "            np.mean(entropies[np.random.choice(len(entropies), size=n_samples_per_pool)])\n",
    "            for _ in range(n_pools)\n",
    "        ])    \n",
    "    \n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    \"pancreas\": {\"name\": \"pancreas\", \"batch_key\": \"study\", \"cell_type_key\": \"cell_type\",\n",
    "                 \"target\": [\"Pancreas SS2\", \"Pancreas CelSeq2\"]},\n",
    "    \"brain\": {\"name\": \"mouse_brain\", \"batch_key\": \"study\", \"cell_type_key\": \"cell_type\",\n",
    "              \"target\": [\"Tabula_muris\", \"Zeisel\"]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.settings.autosave = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [\"brain\", \"peancreas\"]:\n",
    "    data_dict = DATASETS[data]\n",
    "    data_name = data_dict['name']\n",
    "    batch_key = data_dict['batch_key']\n",
    "    cell_type_key = data_dict['cell_type_key']\n",
    "    target_batches = data_dict['target']\n",
    "\n",
    "    adata = sc.read(f\"./data/{data_name}_normalized.h5ad\")\n",
    "\n",
    "\n",
    "    adata.obs['cell_types'] = adata.obs[cell_type_key]\n",
    "    \n",
    "    os.makedirs(f\"./results/Scanorama/{data_name}/\", exist_ok=True)\n",
    "\n",
    "    for i in range(5):\n",
    "        scores = []\n",
    "        for subsample_frac in [0.1, 0.2, 0.4, 0.6, 0.8, 1.0]:\n",
    "            final_adata = None\n",
    "            for target in target_batches:\n",
    "                adata_sampled = adata[adata.obs[batch_key] == target, :]\n",
    "                keep_idx = np.loadtxt(f'./data/subsample/{data_name}/{target}/{subsample_frac}/{i}.csv', dtype='int32')\n",
    "                adata_sampled = adata_sampled[keep_idx, :]\n",
    "\n",
    "                if final_adata is None:\n",
    "                    final_adata = adata_sampled\n",
    "                else:\n",
    "                    final_adata = final_adata.concatenate(adata_sampled)\n",
    "            \n",
    "            adata_list = []\n",
    "            labels_array = np.array([])\n",
    "            batch_array = np.array([])\n",
    "            \n",
    "            for j in final_adata.obs[batch_key].unique():\n",
    "                adata_list.append(final_adata[final_adata.obs[batch_key] == j, :])\n",
    "                labels_array = np.concatenate((labels_array, final_adata.obs[cell_type_key][final_adata.obs[batch_key] == j]))\n",
    "                batch_array = np.concatenate((batch_array, final_adata.obs[batch_key][final_adata.obs[batch_key] == j]))\n",
    "            \n",
    "            print(f\"{subsample_frac}-before\")\n",
    "            sc.pp.neighbors(final_adata)\n",
    "            sc.tl.umap(final_adata)\n",
    "            sc.settings.figdir = f\"./results/Scanorama/{data_name}/{i}/{subsample_frac}/before\"\n",
    "            sc.pl.umap(final_adata, color=[batch_key, cell_type_key], wspace=.5)\n",
    "                \n",
    "            corrected = scanorama.correct_scanpy(adata_list)\n",
    "            final_adata = None\n",
    "            for corrected_adata in corrected:\n",
    "                if final_adata is None:\n",
    "                    final_adata = corrected_adata\n",
    "                else:\n",
    "                    final_adata = final_adata.concatenate(corrected_adata)\n",
    "            \n",
    "            final_adata.obs[batch_key] = batch_array\n",
    "            final_adata.obs[cell_type_key] = labels_array\n",
    "            \n",
    "            sc.tl.pca(final_adata, svd_solver=\"arpack\", n_comps=10)\n",
    "            final_adata = sc.AnnData(X=final_adata.obsm['X_pca'], obs=final_adata.obs)\n",
    "            \n",
    "            asw_score, nmi_score, ari_score = clustering_scores(final_adata.obs[cell_type_key], final_adata.X, final_adata.obs[batch_key])\n",
    "            ebm_scores = []\n",
    "            for k in [15, 25, 50, 100, 200, 300]:\n",
    "                ebm_scores.append(entropy_batch_mixing(final_adata.X, final_adata.obs[batch_key], n_neighbors=k))\n",
    "            \n",
    "            knn_scores = []\n",
    "            for k in [15, 25, 50, 100, 200, 300]:\n",
    "                knn_scores.append(knn_purity(final_adata, label_key=cell_type_key, n_neighbors=k))\n",
    "            \n",
    "            scores.append([subsample_frac, asw_score, ari_score, nmi_score] + ebm_scores + knn_scores)\n",
    "            \n",
    "                \n",
    "            print(f\"{subsample_frac}-after\")\n",
    "            sc.pp.neighbors(final_adata)\n",
    "            sc.tl.umap(final_adata)\n",
    "            sc.settings.figdir = f\"./results/Scanorama/{data_name}/{i}/{subsample_frac}/after\"\n",
    "            sc.pl.umap(final_adata, color=[batch_key, cell_type_key], wspace=.5)\n",
    "            final_adata.write(f\"./results/Scanorama/{data_name}/{i}/{subsample_frac}/result_adata.h5ad\")\n",
    "            \n",
    "        scores = np.array(scores)\n",
    "        np.savetxt(f\"./results/Scanorama/{data_name}/{i}.log\", X=scores, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
